# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.17.3
#   kernelspec:
#     display_name: venv (3.12.10)
#     language: python
#     name: python3
# ---

# %% [markdown]
# # NFL Big Data Bowl 2026 - Deep Analysis: Play Outcomes
#
# This notebook performs advanced analysis by merging all data sources to understand:
# 1. **Complete vs Incomplete passes** - What differentiates success?
# 2. **Situational factors** - Down, distance, quarter effects
# 3. **Player movement signatures** - Do successful plays have distinct convergence patterns?
# 4. **Predictive patterns** - Can we identify success indicators?
#
# **Data Sources**:
# - Input/Output tracking data (player movements)
# - Supplementary data (play outcomes, down/distance, etc.)
# - Convergence metrics (from analysis notebook)

# %% [markdown]
# ## Setup

# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

pd.set_option('display.max_columns', None)

# Visualization settings
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 11

print("âœ… Setup complete!")

# %% [markdown]
# ## 1. Load and Merge All Data Sources

# %%
# Paths
DATA_DIR = Path('../data')
PROCESSED_DIR = DATA_DIR / 'processed'
COMPETITION_DIR = DATA_DIR / '114239_nfl_competition_files_published_analytics_final'
OUTPUT_DIR = PROCESSED_DIR / 'deep_analysis'
OUTPUT_DIR.mkdir(exist_ok=True)

print("Loading data sources...")
print("="*80)

# 1. Load convergence metrics
convergence_df = pd.read_csv(PROCESSED_DIR / 'convergence_speed_all_plays.csv')
print(f"âœ“ Convergence metrics: {len(convergence_df):,} rows")

# 2. Load supplementary data
supp_data = pd.read_csv(COMPETITION_DIR / 'supplementary_data.csv')
print(f"âœ“ Supplementary data: {len(supp_data):,} rows")

print(f"\nSupplementary data columns:")
for col in supp_data.columns:
    print(f"  â€¢ {col}")

# %%
# Explore supplementary data structure
print("\n" + "="*80)
print("SUPPLEMENTARY DATA PREVIEW")
print("="*80)
print(f"\nShape: {supp_data.shape}")
print(f"\nSample data:")
supp_data.head(10)

# %%
print(supp_data['team_coverage_man_zone'].value_counts())
print('='*80)
print(supp_data['team_coverage_type'].value_counts())
print('='*80)
print(supp_data['dropback_type'].value_counts())

# %%
# Check what play outcome information is available
print("\nAvailable play outcome information:")
print("="*80)

# Look for columns related to play outcomes
outcome_cols = [col for col in supp_data.columns if any(word in col.lower() 
                for word in ['pass', 'result', 'complete', 'outcome', 'yards', 'down', 'distance', 'quarter'])]

print(f"\nOutcome-related columns found: {len(outcome_cols)}")
for col in outcome_cols:
    n_unique = supp_data[col].nunique()
    print(f"  â€¢ {col}: {n_unique} unique values")
    if n_unique < 20:
        print(f"    Values: {supp_data[col].unique()[:10]}")

# %%
# Merge convergence data with supplementary data
print("\nMerging datasets...")
print("="*80)

# Identify common columns for merging
common_cols = list(set(convergence_df.columns).intersection(set(supp_data.columns)))
print(f"\nCommon columns for merging: {common_cols}")

# Merge on game_id and play_id
if 'game_id' in common_cols and 'play_id' in common_cols:
    merged_df = convergence_df.merge(
        supp_data,
        on=['game_id', 'play_id'],
        how='left',
        suffixes=('', '_supp')
    )
    
    print(f"\nâœ“ Merged successfully!")
    print(f"  Original convergence rows: {len(convergence_df):,}")
    print(f"  Merged rows: {len(merged_df):,}")
    print(f"  New columns added: {len(merged_df.columns) - len(convergence_df.columns)}")
    
    # Check merge quality
    merge_success_rate = (merged_df[outcome_cols[0]].notna().sum() / len(merged_df) * 100) if outcome_cols else 0
    print(f"  Merge success rate: {merge_success_rate:.1f}%")
else:
    print("\nâš ï¸ Cannot merge - need to identify correct join keys")
    print("Convergence columns:", convergence_df.columns.tolist()[:10])
    print("Supplementary columns:", supp_data.columns.tolist()[:10])

# %%
merged_df.head()

# %% [markdown]
# ## 2. Identify Play Outcomes
#
# Determine which plays were complete vs incomplete passes

# %%
# Assuming merged_df exists, let's identify pass outcomes
# This will depend on what columns are actually in supplementary_data
# Common column names: 'passResult', 'play_description', 'isComplete', etc.

print("Identifying play outcomes...")
print("="*80)

# Search for pass result column
pass_result_cols = [col for col in merged_df.columns if 'pass' in col.lower() and 
                   any(word in col.lower() for word in ['result', 'complete', 'outcome'])]

print(f"\nPotential pass result columns: {pass_result_cols}")

if pass_result_cols:
    result_col = pass_result_cols[0]
    print(f"\nUsing column: '{result_col}'")
    print(f"\nUnique values:")
    print(merged_df[result_col].value_counts())
    
    # Create binary outcome column
    # Adjust this based on actual values in your data
    merged_df['pass_complete'] = merged_df[result_col].isin(['C', 'Complete', 'complete', 1, True])
    
    print(f"\nPass completion breakdown:")
    print(merged_df.groupby('pass_complete').size())
else:
    print("\nâš ï¸ No clear pass result column found. Will need manual identification.")
    print("\nAvailable columns that might help:")
    for col in merged_df.columns:
        if any(word in col.lower() for word in ['desc', 'result', 'outcome', 'yards']):
            print(f"  â€¢ {col}")
print(f"\nColumn: {result_col} - Contextual information:\nC: Complete pass, \nI: Incomplete pass, \nS: Quarterback sack, \nIN: Intercepted pass, \nR: Scramble")

# %%
# Extract situational variables
print("\nExtracting situational variables...")
print("="*80)

situational_vars = {}

# Down
down_cols = [col for col in merged_df.columns if 'down' in col.lower()]
if down_cols:
    situational_vars['down'] = down_cols[0]
    print(f"âœ“ Down: {down_cols[0]}")
    print(f"  Values: {sorted(merged_df[down_cols[0]].dropna().unique())}")

# Distance
dist_cols = [col for col in merged_df.columns if 'distance' in col.lower() or 'togo' in col.lower()]
if dist_cols:
    situational_vars['yards_to_go'] = dist_cols[0]
    print(f"âœ“ Yards to go: {dist_cols[0]}")
    print(f"  Range: {merged_df[dist_cols[0]].min()} - {merged_df[dist_cols[0]].max()}")

# Quarter
quarter_cols = [col for col in merged_df.columns if 'quarter' in col.lower()]
if quarter_cols:
    situational_vars['quarter'] = quarter_cols[0]
    print(f"âœ“ Quarter: {quarter_cols[0]}")
    print(f"  Values: {sorted(merged_df[quarter_cols[0]].dropna().unique())}")

# Yards gained
yards_cols = [col for col in merged_df.columns if 'yards' in col.lower() and 'gain' in col.lower()]
if yards_cols:
    situational_vars['yards_gained'] = yards_cols[0]
    print(f"âœ“ Yards gained: {yards_cols[0]}")

print(f"\nâœ“ Found {len(situational_vars)} situational variables")

# %% [markdown]
# ## 3. Compare Complete vs Incomplete Passes
#
# Analyze convergence patterns for successful vs unsuccessful passes

# %%
# Assuming we have 'pass_complete' column
if 'pass_complete' in merged_df.columns:
    complete = merged_df[merged_df['pass_complete'] == True]
    incomplete = merged_df[merged_df['pass_complete'] == False]
    
    print("="*80)
    print("COMPLETE VS INCOMPLETE PASSES - CONVERGENCE COMPARISON")
    print("="*80)
    
    print(f"\nComplete passes: {len(complete):,} player instances")
    print(f"Incomplete passes: {len(incomplete):,} player instances")
    
    # Compare by role
    roles = ['Defensive Coverage', 'Targeted Receiver']
    
    for role in roles:
        complete_role = complete[complete['player_role'] == role]
        incomplete_role = incomplete[incomplete['player_role'] == role]
        
        if len(complete_role) > 0 and len(incomplete_role) > 0:
            print(f"\n{role}:")
            print(f"  Complete passes:")
            print(f"    Avg convergence: {complete_role['convergence_speed'].mean():.2f} yd/s")
            print(f"    Avg final distance: {complete_role['final_distance'].mean():.2f} yards")
            print(f"    Avg min distance: {complete_role['min_distance'].mean():.2f} yards")
            
            print(f"  Incomplete passes:")
            print(f"    Avg convergence: {incomplete_role['convergence_speed'].mean():.2f} yd/s")
            print(f"    Avg final distance: {incomplete_role['final_distance'].mean():.2f} yards")
            print(f"    Avg min distance: {incomplete_role['min_distance'].mean():.2f} yards")
            
            # Statistical test
            t_stat, p_value = stats.ttest_ind(
                complete_role['convergence_speed'].dropna(),
                incomplete_role['convergence_speed'].dropna()
            )
            print(f"  Statistical significance: p-value = {p_value:.10f} {'(SIGNIFICANT)' if p_value < 0.05 else '(not significant)'}")
else:
    print("âš ï¸ Need to create 'pass_complete' column first based on available data")

# %%
# Visualize complete vs incomplete
if 'pass_complete' in merged_df.columns:
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    roles = ['Defensive Coverage', 'Targeted Receiver']
    
    for idx, role in enumerate(roles):
        role_data = merged_df[merged_df['player_role'] == role]
        complete_role = role_data[role_data['pass_complete'] == True]
        incomplete_role = role_data[role_data['pass_complete'] == False]
        
        # Distribution comparison
        ax = axes[idx, 0]
        ax.hist([complete_role['convergence_speed'], incomplete_role['convergence_speed']],
               bins=40, label=['Complete', 'Incomplete'],
               color=['green', 'red'], alpha=0.6, edgecolor='black')
        ax.axvline(0, color='black', linestyle='-', linewidth=1)
        ax.set_xlabel('Convergence Speed (yd/s)', fontsize=11)
        ax.set_ylabel('Frequency', fontsize=11)
        ax.set_title(f'{role}\nConvergence Speed Distribution', fontsize=12, fontweight='bold')
        ax.legend()
        ax.grid(alpha=0.3)
        
        # Box plot comparison
        ax = axes[idx, 1]
        data_to_plot = [complete_role['convergence_speed'].dropna(),
                       incomplete_role['convergence_speed'].dropna()]
        bp = ax.boxplot(data_to_plot, labels=['Complete', 'Incomplete'],
                       patch_artist=True)
        bp['boxes'][0].set_facecolor('green')
        bp['boxes'][1].set_facecolor('red')
        for box in bp['boxes']:
            box.set_alpha(0.6)
        
        ax.axhline(0, color='black', linestyle='-', linewidth=1)
        ax.set_ylabel('Convergence Speed (yd/s)', fontsize=11)
        ax.set_title(f'{role}\nBox Plot Comparison', fontsize=12, fontweight='bold')
        ax.grid(alpha=0.3, axis='y')
    
    plt.suptitle('Complete vs Incomplete Passes: Convergence Speed Comparison',
                fontsize=15, fontweight='bold')
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'complete_vs_incomplete_convergence.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("âœ… Figure saved!")

# %% [markdown]
# ## 4. Situational Analysis
#
# How do down, distance, and other factors affect convergence and success?

# %%
# Analyze by down
if 'down' in situational_vars and 'pass_complete' in merged_df.columns:
    down_col = situational_vars['down']
    
    print("="*80)
    print("ANALYSIS BY DOWN")
    print("="*80)
    
    defenders = merged_df[merged_df['player_role'] == 'Defensive Coverage']
    
    down_analysis = defenders.groupby(down_col).agg({
        'convergence_speed': 'mean',
        'pass_complete': ['mean', 'count']
    }).round(3)
    
    down_analysis.columns = ['Avg Convergence Speed', 'Completion Rate', 'N Plays']
    print("\n", down_analysis)
    
    # Visualize
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    # Convergence by down
    ax = axes[0]
    down_analysis['Avg Convergence Speed'].plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')
    ax.set_xlabel('Down', fontsize=12)
    ax.set_ylabel('Avg Convergence Speed (yd/s)', fontsize=12)
    ax.set_title('Defensive Convergence by Down', fontsize=13, fontweight='bold')
    ax.grid(alpha=0.3, axis='y')
    ax.tick_params(axis='x', rotation=0)
    
    # Completion rate by down
    ax = axes[1]
    down_analysis['Completion Rate'].plot(kind='bar', ax=ax, color='green', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Down', fontsize=12)
    ax.set_ylabel('Completion Rate', fontsize=12)
    ax.set_title('Pass Completion Rate by Down', fontsize=13, fontweight='bold')
    ax.grid(alpha=0.3, axis='y')
    ax.tick_params(axis='x', rotation=0)
    ax.set_ylim(0, 1)
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'analysis_by_down.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("\nâœ… Figure saved!")

# %%
# Analyze by yards to go (distance)
if 'yards_to_go' in situational_vars and 'pass_complete' in merged_df.columns:
    ytg_col = situational_vars['yards_to_go']
    
    print("="*80)
    print("ANALYSIS BY YARDS TO GO")
    print("="*80)
    
    defenders = merged_df[merged_df['player_role'] == 'Defensive Coverage']
    
    # Create distance categories
    defenders_copy = defenders.copy()
    defenders_copy['distance_category'] = pd.cut(
        defenders_copy[ytg_col],
        bins=[0, 3, 7, 10, 100],
        labels=['Short (0-3)', 'Medium (4-7)', 'Long (8-10)', 'Very Long (10+)']
    )
    
    ytg_analysis = defenders_copy.groupby('distance_category').agg({
        'convergence_speed': 'mean',
        'min_distance': 'mean',
        'pass_complete': ['mean', 'count']
    }).round(3)
    
    ytg_analysis.columns = ['Avg Convergence', 'Avg Min Dist', 'Completion Rate', 'N Plays']
    print("\n", ytg_analysis)
    
    # Visualize
    fig, ax = plt.subplots(figsize=(14, 7))
    
    x = np.arange(len(ytg_analysis))
    width = 0.35
    
    ax.bar(x - width/2, ytg_analysis['Avg Convergence'], width,
          label='Avg Convergence Speed', color='steelblue', edgecolor='black')
    
    ax2 = ax.twinx()
    ax2.bar(x + width/2, ytg_analysis['Completion Rate'], width,
           label='Completion Rate', color='green', edgecolor='black', alpha=0.7)
    
    ax.set_xlabel('Yards to Go Category', fontsize=12)
    ax.set_ylabel('Avg Convergence Speed (yd/s)', fontsize=12, color='steelblue')
    ax2.set_ylabel('Completion Rate', fontsize=12, color='green')
    ax.set_xticks(x)
    ax.set_xticklabels(ytg_analysis.index, rotation=15)
    ax.set_title('Convergence Speed and Completion Rate by Yards to Go',
                fontsize=14, fontweight='bold')
    ax.legend(loc='upper left')
    ax2.legend(loc='upper right')
    ax.grid(alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'analysis_by_yards_to_go.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("\nâœ… Figure saved!")

# %% [markdown]
# ## 5. Movement Signature Analysis
#
# Do successful plays have distinct movement patterns?

# %%
# Analyze movement signatures for successful vs unsuccessful plays
if 'pass_complete' in merged_df.columns:
    print("="*80)
    print("MOVEMENT SIGNATURE ANALYSIS")
    print("="*80)
    
    # Focus on defenders
    defenders = merged_df[merged_df['player_role'] == 'Defensive Coverage']
    
    # Create signature metrics
    signature_metrics = {
        'convergence_speed': 'How fast they close',
        'initial_distance': 'Starting position',
        'final_distance': 'Final position',
        'min_distance': 'Closest approach',
        'distance_change': 'Total distance closed',
        'avg_speed': 'Average speed',
        'max_speed': 'Peak speed',
        'time_elapsed': 'Time tracked'
    }
    
    complete_defenders = defenders[defenders['pass_complete'] == True]
    incomplete_defenders = defenders[defenders['pass_complete'] == False]
    
    print("\nSignature Metrics Comparison:")
    print("-" * 80)
    print(f"{'Metric':<25} {'Complete':<15} {'Incomplete':<15} {'Difference':<15} {'Sig?'}")
    print("-" * 80)
    
    for metric, description in signature_metrics.items():
        if metric in defenders.columns:
            complete_mean = complete_defenders[metric].mean()
            incomplete_mean = incomplete_defenders[metric].mean()
            diff = complete_mean - incomplete_mean
            
            # T-test
            t_stat, p_value = stats.ttest_ind(
                complete_defenders[metric].dropna(),
                incomplete_defenders[metric].dropna()
            )
            
            sig = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else ""
            
            print(f"{metric:<25} {complete_mean:>14.2f} {incomplete_mean:>14.2f} {diff:>+14.2f} {sig:>5}")

# %%
# Visualize signature differences
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

key_metrics = ['convergence_speed', 'min_distance', 'avg_speed', 'distance_change']

for idx, metric in enumerate(key_metrics):
    ax = axes[idx // 2, idx % 2]
    
    if metric in defenders.columns:
        # Violin plot
        data_complete = complete_defenders[metric].dropna()
        data_incomplete = incomplete_defenders[metric].dropna()
        
        parts = ax.violinplot([data_complete, data_incomplete],
                                positions=[1, 2],
                                showmeans=True,
                                showmedians=True)
        
        for pc, color in zip(parts['bodies'], ['green', 'red']):
            pc.set_facecolor(color)
            pc.set_alpha(0.6)
        
        ax.set_xticks([1, 2])
        ax.set_xticklabels(['Complete', 'Incomplete'])
        ax.set_ylabel(metric.replace('_', ' ').title(), fontsize=11)
        ax.set_title(f'{metric.replace("_", " ").title()}\nDistribution Comparison',
                    fontsize=12, fontweight='bold')
        ax.grid(alpha=0.3, axis='y')
        
        # Add statistical annotation
        t_stat, p_value = stats.ttest_ind(data_complete, data_incomplete)
        sig_text = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"
        ax.text(0.5, 0.95, f'p-value: {p_value:.4f} {sig_text}',
                transform=ax.transAxes, ha='center', va='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                fontsize=9)

plt.suptitle('Movement Signatures: Complete vs Incomplete Passes (Defenders)',
            fontsize=15, fontweight='bold')
plt.tight_layout()
plt.savefig(OUTPUT_DIR / 'movement_signatures.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nâœ… Figure saved!")

# %% [markdown]
# ## 6. Receiver Analysis: Successful vs Unsuccessful

# %%
# Analyze receiver movement for complete vs incomplete
if 'pass_complete' in merged_df.columns:
    print("="*80)
    print("RECEIVER MOVEMENT ANALYSIS")
    print("="*80)
    
    receivers = merged_df[merged_df['player_role'] == 'Targeted Receiver']
    
    if len(receivers) > 0:
        complete_rec = receivers[receivers['pass_complete'] == True]
        incomplete_rec = receivers[receivers['pass_complete'] == False]
        
        print("\nReceiver Metrics:")
        print("-" * 80)
        print(f"{'Metric':<25} {'Complete':<15} {'Incomplete':<15} {'Difference':<15}")
        print("-" * 80)
        
        for metric in ['convergence_speed', 'min_distance', 'avg_speed', 'initial_distance']:
            if metric in receivers.columns:
                complete_mean = complete_rec[metric].mean()
                incomplete_mean = incomplete_rec[metric].mean()
                diff = complete_mean - incomplete_mean
                
                print(f"{metric:<25} {complete_mean:>14.2f} {incomplete_mean:>14.2f} {diff:>+14.2f}")
        
        # Key insight: Do successful receivers converge faster?
        print("\nKEY INSIGHT:")
        rec_conv_diff = complete_rec['convergence_speed'].mean() - incomplete_rec['convergence_speed'].mean()
        print(f"Receivers on complete passes converge {rec_conv_diff:+.2f} yards/sec compared to incomplete")
        
        rec_dist_diff = complete_rec['min_distance'].mean() - incomplete_rec['min_distance'].mean()
        print(f"Receivers on complete passes get {rec_dist_diff:+.2f} yards closer to ball landing spot")

# %% [markdown]
# ## 7. Create Success Predictor Score
#
# Combine metrics to create a "success probability" indicator

# %%
# Create a simple success score based on key metrics
if 'pass_complete' in merged_df.columns:
    print("="*80)
    print("SUCCESS PREDICTOR ANALYSIS")
    print("="*80)
    
    # Focus on plays (aggregate to play level)
    defenders = merged_df[merged_df['player_role'] == 'Defensive Coverage']
    receivers = merged_df[merged_df['player_role'] == 'Targeted Receiver']
    
    # Aggregate to play level
    play_level_def = defenders.groupby(['game_id', 'play_id']).agg({
        'convergence_speed': 'mean',
        'min_distance': 'min',
        'avg_speed': 'mean',
        'pass_complete': 'first'
    }).reset_index()
    
    play_level_def.columns = ['game_id', 'play_id', 'def_avg_conv', 'def_min_dist', 
                              'def_avg_speed', 'pass_complete']
    
    if len(receivers) > 0:
        play_level_rec = receivers.groupby(['game_id', 'play_id']).agg({
            'convergence_speed': 'mean',
            'min_distance': 'min'
        }).reset_index()
        
        play_level_rec.columns = ['game_id', 'play_id', 'rec_avg_conv', 'rec_min_dist']
        
        # Merge
        play_level = play_level_def.merge(play_level_rec, on=['game_id', 'play_id'], how='left')
    else:
        play_level = play_level_def
    
    # Create success score (normalize metrics)
    from sklearn.preprocessing import StandardScaler
    
    features = ['def_avg_conv', 'def_min_dist', 'def_avg_speed']
    if 'rec_avg_conv' in play_level.columns:
        features.extend(['rec_avg_conv', 'rec_min_dist'])
    
    # Remove NaN
    play_level_clean = play_level.dropna(subset=features + ['pass_complete'])
    
    # Standardize
    scaler = StandardScaler()
    X = scaler.fit_transform(play_level_clean[features])
    y = play_level_clean['pass_complete'].astype(int)
    
    # Logistic regression
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report, roc_auc_score, roc_curve
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    model = LogisticRegression(random_state=42, max_iter=1000)
    model.fit(X_train, y_train)
    
    # Predictions
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    print("\nModel Performance:")
    print("-" * 80)
    print(classification_report(y_test, y_pred, target_names=['Incomplete', 'Complete']))
    
    auc_score = roc_auc_score(y_test, y_pred_proba)
    print(f"\nAUC-ROC Score: {auc_score:.3f}")
    
    # Feature importance
    print("\nFeature Importance (Coefficients):")
    print("-" * 80)
    for feature, coef in zip(features, model.coef_[0]):
        print(f"  {feature:<25} {coef:>10.3f}")

# %%
# Plot ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# ROC Curve
ax = axes[0]
ax.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc_score:.3f})')
ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')
ax.set_xlabel('False Positive Rate', fontsize=12)
ax.set_ylabel('True Positive Rate', fontsize=12)
ax.set_title('ROC Curve: Predicting Pass Completion', fontsize=13, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(alpha=0.3)

# Feature importance
ax = axes[1]
feature_imp = pd.DataFrame({
    'Feature': features,
    'Coefficient': model.coef_[0]
}).sort_values('Coefficient')

colors = ['red' if x < 0 else 'green' for x in feature_imp['Coefficient']]
ax.barh(range(len(feature_imp)), feature_imp['Coefficient'], color=colors, edgecolor='black', alpha=0.7)
ax.set_yticks(range(len(feature_imp)))
ax.set_yticklabels(feature_imp['Feature'])
ax.set_xlabel('Coefficient (Impact on Completion)', fontsize=12)
ax.set_title('Feature Importance in Predicting Success', fontsize=13, fontweight='bold')
ax.axvline(0, color='black', linestyle='-', linewidth=1)
ax.grid(alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig(OUTPUT_DIR / 'success_predictor_model.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nâœ… Figure saved!")

print(f"""
**ROC** = Receiver Operating Characteristic **AUC** = Area Under the Curve

**Your AUC = 0.719**

### What This Means:

**Interpretation Scale**:

- **AUC = 0.5**: Random guessing (coin flip) - the dashed diagonal line
- **AUC = 0.7-0.8**: Good predictive model âœ… (You're here!)
- **AUC = 0.8-0.9**: Excellent model
- **AUC > 0.9**: Outstanding model
- **AUC = 1.0**: Perfect predictions

**Your 0.719 means**: If you randomly pick one complete pass and one incomplete pass, your model will correctly identify which is which **71.9% of the time**.

### How to Read the ROC Curve:

**Axes**:

- **X-axis (False Positive Rate)**: How often you incorrectly predict "complete" when it's actually incomplete
- **Y-axis (True Positive Rate)**: How often you correctly predict "complete" when it is complete

**The Curve**:

- Your blue curve is **well above the diagonal** = your model is much better than random guessing
- The closer to the top-left corner, the better
- The area between your curve and the diagonal represents your model's improvement over random chance

**What This Tells You**: Your convergence metrics (defender min distance, receiver convergence, etc.) can predict pass completion with **moderate-to-good accuracy**. This validates that convergence patterns meaningfully predict outcomes!
      
{'='*80}
      
**def_min_dist (~+0.43)**: Moderate positive predictor
    - When defenders stay FARTHER from the ball â†’ more completions
    - Makes sense: more defensive separation = easier catches for receivers
2. **rec_avg_conv (~+0.23)**: Moderate positive predictor
    - When receivers converge FASTER toward the ball â†’ more completions
    - Makes sense: receivers actively working toward the catch point increases completion probability
3. **def_avg_speed (~-0.01)**: Nearly zero impact
    - Defender speed has virtually no predictive power
    - Suggests it's not HOW FAST defenders are moving, but WHERE they are positioned that matters
4. **def_avg_conv (~-0.25)**: Moderate negative predictor
    - When defenders converge FASTER toward the ball â†’ more incompletions
    - Makes sense: defenders closing in on the catch point disrupts passes
5. **rec_min_dist (~-1.0)**: LARGEST negative predictor (most important feature)
    - When receivers are FARTHER from the ball â†’ more incompletions
    - Makes perfect sense: this is the most critical factor - you can't complete passes when receivers aren't near the ball
      """)

# %% [markdown]
# ## 8. Deep Dive: High vs Low Success Plays

# %%
# Identify plays with extreme convergence patterns
if 'pass_complete' in merged_df.columns:
    print("="*80)
    print("EXTREME CONVERGENCE PATTERNS")
    print("="*80)
    
    defenders = merged_df[merged_df['player_role'] == 'Defensive Coverage']
    
    # Calculate play-level defensive convergence
    play_conv = defenders.groupby(['game_id', 'play_id']).agg({
        'convergence_speed': 'mean',
        'min_distance': 'min',
        'pass_complete': 'first'
    }).reset_index()
    
    # Top 10% fastest defensive convergence
    top_conv_threshold = play_conv['convergence_speed'].quantile(0.90)
    top_conv_plays = play_conv[play_conv['convergence_speed'] >= top_conv_threshold]
    
    # Bottom 10%
    bottom_conv_threshold = play_conv['convergence_speed'].quantile(0.10)
    bottom_conv_plays = play_conv[play_conv['convergence_speed'] <= bottom_conv_threshold]
    
    print(f"\nTop 10% Defensive Convergence (>{top_conv_threshold:.2f} yd/s):")
    print(f"  Total plays: {len(top_conv_plays)}")
    print(f"  Completion rate: {top_conv_plays['pass_complete'].mean()*100:.1f}%")
    print(f"  Avg min distance: {top_conv_plays['min_distance'].mean():.2f} yards")
    
    print(f"\nBottom 10% Defensive Convergence (<{bottom_conv_threshold:.2f} yd/s):")
    print(f"  Total plays: {len(bottom_conv_plays)}")
    print(f"  Completion rate: {bottom_conv_plays['pass_complete'].mean()*100:.1f}%")
    print(f"  Avg min distance: {bottom_conv_plays['min_distance'].mean():.2f} yards")
    
    # Statistical comparison
    chi2, p_value = stats.chi2_contingency([
        [top_conv_plays['pass_complete'].sum(), len(top_conv_plays) - top_conv_plays['pass_complete'].sum()],
        [bottom_conv_plays['pass_complete'].sum(), len(bottom_conv_plays) - bottom_conv_plays['pass_complete'].sum()]
    ])[:2]
    
    print(f"\nStatistical test: Chi-square p-value = {p_value:.4f}")
    print(f"{'SIGNIFICANT difference' if p_value < 0.05 else 'No significant difference'} in completion rates")

# %% [markdown]
# ## 9. Summary Report

# %%
# Generate comprehensive summary
if 'pass_complete' in merged_df.columns:
    print("="*80)
    print("DEEP ANALYSIS SUMMARY REPORT")
    print("="*80)
    
    defenders = merged_df[merged_df['player_role'] == 'Defensive Coverage']
    receivers = merged_df[merged_df['player_role'] == 'Targeted Receiver']
    
    complete_def = defenders[defenders['pass_complete'] == True]
    incomplete_def = defenders[defenders['pass_complete'] == False]
    
    print(f"""
DATASET:
â€¢ Total plays with outcome data: {merged_df.groupby(['game_id', 'play_id']).ngroups:,}
â€¢ Complete passes: {merged_df['pass_complete'].sum():,} ({merged_df['pass_complete'].mean()*100:.1f}%)
â€¢ Incomplete passes: {(~merged_df['pass_complete']).sum():,} ({(1-merged_df['pass_complete'].mean())*100:.1f}%)

DEFENSIVE CONVERGENCE SIGNATURES:
Complete Passes:
  â€¢ Avg convergence speed: {complete_def['convergence_speed'].mean():.2f} yd/s
  â€¢ Avg closest approach: {complete_def['min_distance'].mean():.2f} yards
  â€¢ Avg final distance: {complete_def['final_distance'].mean():.2f} yards

Incomplete Passes:
  â€¢ Avg convergence speed: {incomplete_def['convergence_speed'].mean():.2f} yd/s
  â€¢ Avg closest approach: {incomplete_def['min_distance'].mean():.2f} yards
  â€¢ Avg final distance: {incomplete_def['final_distance'].mean():.2f} yards

KEY FINDINGS:
1. Defenders on incomplete passes converge {incomplete_def['convergence_speed'].mean() - complete_def['convergence_speed'].mean():+.2f} yd/s FASTER
2. Defenders get {incomplete_def['min_distance'].mean() - complete_def['min_distance'].mean():+.2f} yards CLOSER on incomplete passes
3. This suggests better defensive convergence leads to more incompletions

ACTIONABLE INSIGHTS:
â€¢ Fast defensive convergence (>90th percentile) correlates with lower completion rates
â€¢ Starting distance matters: closer defenders have higher impact
â€¢ Receiver convergence speed is {receivers['convergence_speed'].mean():.2f} yd/s on average

FILES GENERATED:
âœ“ complete_vs_incomplete_convergence.png
âœ“ analysis_by_down.png  
âœ“ analysis_by_yards_to_go.png
âœ“ movement_signatures.png
âœ“ success_predictor_model.png
""")
    
    print("="*80)
    print("âœ… DEEP ANALYSIS COMPLETE!")
    print("="*80)

# %%
print("\nAll analysis files saved to:")
print(f"  {OUTPUT_DIR.absolute()}")
print("\nGenerated files:")
for file in sorted(OUTPUT_DIR.glob('*.png')):
    print(f"  âœ“ {file.name}")

print("\nðŸŽ‰ Deep analysis complete! You now have insights into what makes passes successful.")

# %%
