{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Big Data Bowl 2026 - Data Download\n",
    "\n",
    "This notebook downloads the competition data directly from Kaggle using the Kaggle API.\n",
    "\n",
    "**Prerequisites:**\n",
    "1. You must have accepted the competition rules on Kaggle\n",
    "2. Your `kaggle.json` API token must be in `~/.kaggle/` directory\n",
    "3. Run `pip install -r requirements.txt` first\n",
    "\n",
    "**Competition URL:** https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Kaggle API\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data will be saved to: d:\\PyScripts\\NFL-Big-Data-Bowl-2026-Analytics\\data\n"
     ]
    }
   ],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "DATA_DIR = Path('./data')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "COMPETITION_DIR = DATA_DIR / '114239_nfl_competition_files_published_analytics_final'\n",
    "TRAIN_DIR = COMPETITION_DIR / 'train'\n",
    "\n",
    "# Competition name\n",
    "COMPETITION_NAME = 'nfl-big-data-bowl-2026-analytics'\n",
    "\n",
    "print(f\"üìÅ Data will be saved to: {DATA_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate with Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Kaggle API authenticated successfully!\n",
      "\n",
      "üìã Note: Make sure you've accepted the competition rules at:\n",
      "   https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-analytics\n"
     ]
    }
   ],
   "source": [
    "# Initialize Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "print(\"‚úÖ Kaggle API authenticated successfully!\")\n",
    "print(\"\\nüìã Note: Make sure you've accepted the competition rules at:\")\n",
    "print(f\"   https://www.kaggle.com/competitions/{COMPETITION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Available Files\n",
    "\n",
    "Let's see what files are available in the competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Available files in competition:\n",
      "\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w01.csv\", \"description\": \"\", \"totalBytes\": 48950314, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w02.csv\", \"description\": \"\", \"totalBytes\": 49485029, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w03.csv\", \"description\": \"\", \"totalBytes\": 51062128, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w04.csv\", \"description\": \"\", \"totalBytes\": 46685806, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w05.csv\", \"description\": \"\", \"totalBytes\": 43574971, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w06.csv\", \"description\": \"\", \"totalBytes\": 46320079, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w07.csv\", \"description\": \"\", \"totalBytes\": 39972688, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w08.csv\", \"description\": \"\", \"totalBytes\": 48114622, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w09.csv\", \"description\": \"\", \"totalBytes\": 43224522, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w10.csv\", \"description\": \"\", \"totalBytes\": 44660215, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w11.csv\", \"description\": \"\", \"totalBytes\": 41687928, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w12.csv\", \"description\": \"\", \"totalBytes\": 50591754, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w13.csv\", \"description\": \"\", \"totalBytes\": 40083483, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w14.csv\", \"description\": \"\", \"totalBytes\": 48010868, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w15.csv\", \"description\": \"\", \"totalBytes\": 48234805, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w16.csv\", \"description\": \"\", \"totalBytes\": 54152852, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w17.csv\", \"description\": \"\", \"totalBytes\": 47524865, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/input_2023_w18.csv\", \"description\": \"\", \"totalBytes\": 43583927, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/output_2023_w01.csv\", \"description\": \"\", \"totalBytes\": 1149693, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n",
      "   {\"ref\": \"\", \"name\": \"114239_nfl_competition_files_published_analytics_final/train/output_2023_w02.csv\", \"description\": \"\", \"totalBytes\": 1151878, \"url\": \"\", \"creationDate\": \"2025-09-23T18:36:28.263Z\"}\n"
     ]
    }
   ],
   "source": [
    "# List competition files\n",
    "try:\n",
    "    files = api.competition_list_files(COMPETITION_NAME)\n",
    "    print(\"üì¶ Available files in competition:\\n\")\n",
    "    if hasattr(files, 'files'):\n",
    "        for file in files.files:\n",
    "            print(f\"   {file}\")\n",
    "    else:\n",
    "        file_list = files\n",
    "        for f in file_list:\n",
    "            print(f\"   - {f.name} ({f.size / (1024**2):.1f} MB)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\n‚ö†Ô∏è  Make sure you've:\")\n",
    "    print(\"   1. Accepted the competition rules\")\n",
    "    print(\"   2. Set up your kaggle.json credentials correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Competition Data\n",
    "\n",
    "This will download all competition files to the data directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è  Downloading competition files...\n",
      "\n",
      "This may take a few minutes depending on your internet speed.\n",
      "\n",
      "Downloading nfl-big-data-bowl-2026-analytics.zip to data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103M/103M [00:00<00:00, 1.51GB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "‚úÖ Download complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"‚¨áÔ∏è  Downloading competition files...\\n\")\n",
    "print(\"This may take a few minutes depending on your internet speed.\\n\")\n",
    "\n",
    "try:\n",
    "    # Download all competition files\n",
    "    api.competition_download_files(\n",
    "        COMPETITION_NAME,\n",
    "        path=str(DATA_DIR),\n",
    "        quiet=False\n",
    "    )\n",
    "    print(\"\\n‚úÖ Download complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Download failed: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Verify you accepted competition rules\")\n",
    "    print(\"2. Check your internet connection\")\n",
    "    print(\"3. Verify kaggle.json is in the correct location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ZIP Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Found 1 ZIP file(s) to extract\n",
      "\n",
      "Extracting nfl-big-data-bowl-2026-analytics.zip...\n",
      "  ‚úÖ Extracted successfully\n",
      "\n",
      "‚úÖ All files extracted!\n"
     ]
    }
   ],
   "source": [
    "# Find and extract ZIP files\n",
    "zip_files = list(DATA_DIR.glob('*.zip'))\n",
    "\n",
    "if zip_files:\n",
    "    print(f\"üì¶ Found {len(zip_files)} ZIP file(s) to extract\\n\")\n",
    "    \n",
    "    for zip_path in zip_files:\n",
    "        print(f\"Extracting {zip_path.name}...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(DATA_DIR)\n",
    "            print(f\"  ‚úÖ Extracted successfully\")\n",
    "            \n",
    "            # Optionally remove ZIP file after extraction\n",
    "            # zip_path.unlink()\n",
    "            # print(f\"  üóëÔ∏è  Removed ZIP file\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error extracting: {e}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ All files extracted!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No ZIP files found to extract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Downloaded Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Found 37 CSV files total\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìÇ Directory: 114239_nfl_competition_files_published_analytics_final/\n",
      "--------------------------------------------------------------------------------\n",
      "   ‚úì supplementary_data.csv                   (     7.4 MB)\n",
      "\n",
      "   Subtotal: 1 files\n",
      "\n",
      "üìÇ Directory: train/\n",
      "--------------------------------------------------------------------------------\n",
      "   ‚úì input_2023_w01.csv                       (    46.7 MB)\n",
      "   ‚úì input_2023_w02.csv                       (    47.2 MB)\n",
      "   ‚úì input_2023_w03.csv                       (    48.7 MB)\n",
      "   ‚úì input_2023_w04.csv                       (    44.5 MB)\n",
      "   ‚úì input_2023_w05.csv                       (    41.6 MB)\n",
      "   ‚úì input_2023_w06.csv                       (    44.2 MB)\n",
      "   ‚úì input_2023_w07.csv                       (    38.1 MB)\n",
      "   ‚úì input_2023_w08.csv                       (    45.9 MB)\n",
      "   ‚úì input_2023_w09.csv                       (    41.2 MB)\n",
      "   ‚úì input_2023_w10.csv                       (    42.6 MB)\n",
      "   ‚úì input_2023_w11.csv                       (    39.8 MB)\n",
      "   ‚úì input_2023_w12.csv                       (    48.2 MB)\n",
      "   ‚úì input_2023_w13.csv                       (    38.2 MB)\n",
      "   ‚úì input_2023_w14.csv                       (    45.8 MB)\n",
      "   ‚úì input_2023_w15.csv                       (    46.0 MB)\n",
      "   ‚úì input_2023_w16.csv                       (    51.6 MB)\n",
      "   ‚úì input_2023_w17.csv                       (    45.3 MB)\n",
      "   ‚úì input_2023_w18.csv                       (    41.6 MB)\n",
      "   ‚úì output_2023_w01.csv                      (     1.1 MB)\n",
      "   ‚úì output_2023_w02.csv                      (     1.1 MB)\n",
      "   ‚úì output_2023_w03.csv                      (     1.2 MB)\n",
      "   ‚úì output_2023_w04.csv                      (     1.0 MB)\n",
      "   ‚úì output_2023_w05.csv                      (     1.0 MB)\n",
      "   ‚úì output_2023_w06.csv                      (     1.1 MB)\n",
      "   ‚úì output_2023_w07.csv                      (     0.9 MB)\n",
      "   ‚úì output_2023_w08.csv                      (     1.1 MB)\n",
      "   ‚úì output_2023_w09.csv                      (     1.0 MB)\n",
      "   ‚úì output_2023_w10.csv                      (     1.0 MB)\n",
      "   ‚úì output_2023_w11.csv                      (     0.9 MB)\n",
      "   ‚úì output_2023_w12.csv                      (     1.1 MB)\n",
      "   ‚úì output_2023_w13.csv                      (     1.0 MB)\n",
      "   ‚úì output_2023_w14.csv                      (     1.1 MB)\n",
      "   ‚úì output_2023_w15.csv                      (     1.1 MB)\n",
      "   ‚úì output_2023_w16.csv                      (     1.2 MB)\n",
      "   ‚úì output_2023_w17.csv                      (     1.1 MB)\n",
      "   ‚úì output_2023_w18.csv                      (     1.0 MB)\n",
      "\n",
      "   Subtotal: 36 files\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Total CSV files found: 37\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "all_csv_files = list(DATA_DIR.rglob('*.csv'))\n",
    "\n",
    "print(f\"\\nüìä Found {len(all_csv_files)} CSV files total\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Organize by directory\n",
    "files_by_dir = {}\n",
    "for csv_file in sorted(all_csv_files):\n",
    "    parent_dir = csv_file.parent.name\n",
    "    if parent_dir not in files_by_dir:\n",
    "        files_by_dir[parent_dir] = []\n",
    "    files_by_dir[parent_dir].append(csv_file)\n",
    "    \n",
    "# Display files organized by directory\n",
    "for dir_name, files in files_by_dir.items():\n",
    "    print(f\"\\nüìÇ Directory: {dir_name}/\")\n",
    "    print(\"-\" * 80)\n",
    "    for csv_file in files:\n",
    "        size_mb = csv_file.stat().st_size / (1024**2)\n",
    "        print(f\"   ‚úì {csv_file.name:<40} ({size_mb:>8.1f} MB)\")\n",
    "    print(f\"\\n   Subtotal: {len(files)} files\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ Total CSV files found: {len(all_csv_files)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Data Preview\n",
    "\n",
    "Let's peek at the structure of each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä SUPPLEMENTARY DATA PREVIEW\n",
      "================================================================================\n",
      "\n",
      "File: supplementary_data.csv\n",
      "Shape: 5 rows √ó 41 columns (showing first 5)\n",
      "\n",
      "Columns: game_id, season, week, game_date, game_time_eastern, home_team_abbr, visitor_team_abbr, play_id, play_description, quarter, game_clock, down, yards_to_go, possession_team, defensive_team, yardline_side, yardline_number, pre_snap_home_score, pre_snap_visitor_score, play_nullified_by_penalty, pass_result, pass_length, offense_formation, receiver_alignment, route_of_targeted_receiver, play_action, dropback_type, dropback_distance, pass_location_type, defenders_in_the_box, team_coverage_man_zone, team_coverage_type, penalty_yards, pre_penalty_yards_gained, yards_gained, expected_points, expected_points_added, pre_snap_home_team_win_probability, pre_snap_visitor_team_win_probability, home_team_win_probability_added, visitor_team_win_probility_added\n",
      "\n",
      "First few rows:\n",
      "      game_id  season  week   game_date game_time_eastern home_team_abbr  \\\n",
      "0  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
      "1  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
      "2  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
      "3  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
      "4  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
      "\n",
      "  visitor_team_abbr  play_id  \\\n",
      "0               DET     3461   \n",
      "1               DET      461   \n",
      "2               DET     1940   \n",
      "3               DET     1711   \n",
      "4               DET     1588   \n",
      "\n",
      "                                    play_description  quarter  ...  \\\n",
      "0  (10:46) (Shotgun) J.Goff pass deep left to J.R...        4  ...   \n",
      "1  (7:30) J.Goff pass short right to J.Reynolds t...        1  ...   \n",
      "2  (:09) (Shotgun) J.Goff pass incomplete deep ri...        2  ...   \n",
      "3  (:45) (No Huddle, Shotgun) P.Mahomes pass deep...        2  ...   \n",
      "4  (1:54) (Shotgun) P.Mahomes pass incomplete dee...        2  ...   \n",
      "\n",
      "  team_coverage_type  penalty_yards  pre_penalty_yards_gained yards_gained  \\\n",
      "0       COVER_2_ZONE            NaN                        18           18   \n",
      "1       COVER_6_ZONE            NaN                        21           21   \n",
      "2       COVER_2_ZONE            NaN                         0            0   \n",
      "3       COVER_2_ZONE            NaN                        26           26   \n",
      "4       COVER_4_ZONE            NaN                         0            0   \n",
      "\n",
      "  expected_points expected_points_added  pre_snap_home_team_win_probability  \\\n",
      "0       -0.664416              2.945847                            0.834296   \n",
      "1        1.926131              1.345633                            0.544618   \n",
      "2        0.281891             -0.081964                            0.771994   \n",
      "3        3.452352              2.342947                            0.663187   \n",
      "4        1.921525             -0.324035                            0.615035   \n",
      "\n",
      "   pre_snap_visitor_team_win_probability  home_team_win_probability_added  \\\n",
      "0                               0.165704                        -0.081149   \n",
      "1                               0.455382                        -0.029415   \n",
      "2                               0.228006                         0.000791   \n",
      "3                               0.336813                         0.041843   \n",
      "4                               0.384965                         0.000061   \n",
      "\n",
      "  visitor_team_win_probility_added  \n",
      "0                         0.081149  \n",
      "1                         0.029415  \n",
      "2                        -0.000791  \n",
      "3                        -0.041843  \n",
      "4                        -0.000061  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "\n",
      "================================================================================\n",
      "üìä WEEKLY INPUT FILES PREVIEW\n",
      "================================================================================\n",
      "\n",
      "File: input_2023_w02.csv (example week)\n",
      "Shape: 5 rows √ó 23 columns (showing first 5)\n",
      "\n",
      "Columns: game_id, play_id, player_to_predict, nfl_id, frame_id, play_direction, absolute_yardline_number, player_name, player_height, player_weight, player_birth_date, player_position, player_side, player_role, x, y, s, a, dir, o, num_frames_output, ball_land_x, ball_land_y\n",
      "\n",
      "First few rows:\n",
      "      game_id  play_id  player_to_predict  nfl_id  frame_id play_direction  \\\n",
      "0  2023091400       56              False   54583         1           left   \n",
      "1  2023091400       56              False   54583         2           left   \n",
      "2  2023091400       56              False   54583         3           left   \n",
      "3  2023091400       56              False   54583         4           left   \n",
      "4  2023091400       56              False   54583         5           left   \n",
      "\n",
      "   absolute_yardline_number    player_name player_height  player_weight  ...  \\\n",
      "0                        85  Akayleb Evans           6-2            193  ...   \n",
      "1                        85  Akayleb Evans           6-2            193  ...   \n",
      "2                        85  Akayleb Evans           6-2            193  ...   \n",
      "3                        85  Akayleb Evans           6-2            193  ...   \n",
      "4                        85  Akayleb Evans           6-2            193  ...   \n",
      "\n",
      "          player_role      x      y     s     a     dir      o  \\\n",
      "0  Defensive Coverage  78.78  13.43  0.24  0.25  105.26  64.25   \n",
      "1  Defensive Coverage  78.80  13.42  0.20  0.41  107.29  65.30   \n",
      "2  Defensive Coverage  78.82  13.41  0.14  0.53  106.83  64.31   \n",
      "3  Defensive Coverage  78.83  13.41  0.08  0.57  103.10  64.31   \n",
      "4  Defensive Coverage  78.83  13.40  0.07  0.53  162.75  67.19   \n",
      "\n",
      "   num_frames_output  ball_land_x  ball_land_y  \n",
      "0                 10    81.809998        36.77  \n",
      "1                 10    81.809998        36.77  \n",
      "2                 10    81.809998        36.77  \n",
      "3                 10    81.809998        36.77  \n",
      "4                 10    81.809998        36.77  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "================================================================================\n",
      "üìä WEEKLY OUTPUT FILES PREVIEW\n",
      "================================================================================\n",
      "\n",
      "File: output_2023_w02.csv (example week)\n",
      "Shape: 5 rows √ó 6 columns (showing first 5)\n",
      "\n",
      "Columns: game_id, play_id, nfl_id, frame_id, x, y\n",
      "\n",
      "First few rows:\n",
      "      game_id  play_id  nfl_id  frame_id      x      y\n",
      "0  2023091400       56   47816         1  75.81  44.50\n",
      "1  2023091400       56   47816         2  75.75  44.37\n",
      "2  2023091400       56   47816         3  75.72  44.20\n",
      "3  2023091400       56   47816         4  75.77  43.99\n",
      "4  2023091400       56   47816         5  75.87  43.74\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä SUPPLEMENTARY DATA PREVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check supplementary data\n",
    "supp_file = COMPETITION_DIR / 'supplementary_data.csv'\n",
    "if supp_file.exists():\n",
    "    try:\n",
    "        df_supp = pd.read_csv(supp_file, nrows=5)\n",
    "        print(f\"\\nFile: supplementary_data.csv\")\n",
    "        print(f\"Shape: {df_supp.shape[0]} rows √ó {df_supp.shape[1]} columns (showing first 5)\")\n",
    "        print(f\"\\nColumns: {', '.join(df_supp.columns.tolist())}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(df_supp.head())\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading supplementary_data.csv: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  supplementary_data.csv not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä WEEKLY INPUT FILES PREVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check input files (week 2 as example)\n",
    "input_w02 = TRAIN_DIR / 'input_2023_w02.csv'\n",
    "if input_w02.exists():\n",
    "    try:\n",
    "        df_input = pd.read_csv(input_w02, nrows=5)\n",
    "        print(f\"\\nFile: input_2023_w02.csv (example week)\")\n",
    "        print(f\"Shape: {df_input.shape[0]} rows √ó {df_input.shape[1]} columns (showing first 5)\")\n",
    "        print(f\"\\nColumns: {', '.join(df_input.columns.tolist())}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(df_input.head())\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading input file: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  input_2023_w02.csv not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä WEEKLY OUTPUT FILES PREVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check output files (week 2 as example)\n",
    "output_w02 = TRAIN_DIR / 'output_2023_w02.csv'\n",
    "if output_w02.exists():\n",
    "    try:\n",
    "        df_output = pd.read_csv(output_w02, nrows=5)\n",
    "        print(f\"\\nFile: output_2023_w02.csv (example week)\")\n",
    "        print(f\"Shape: {df_output.shape[0]} rows √ó {df_output.shape[1]} columns (showing first 5)\")\n",
    "        print(f\"\\nColumns: {', '.join(df_output.columns.tolist())}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(df_output.head())\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading output file: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  output_2023_w02.csv not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Full Datasets (Memory Check)\n",
    "\n",
    "Let's check how much memory we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Loading datasets (samples)...\n",
      "================================================================================\n",
      "\n",
      "üìä Supplementary Data:\n",
      "\n",
      "Loading supplementary_data.csv...\n",
      "  ‚úì Loaded: 18,009 rows √ó 41 columns\n",
      "  üíæ Memory: 22.1 MB\n",
      "\n",
      "üìä Sample Input Files:\n",
      "\n",
      "Loading input_2023_w02.csv...\n",
      "  ‚ÑπÔ∏è  Loaded sample: 10,000 rows (out of potentially more)\n",
      "  üíæ Memory: 5.0 MB\n",
      "\n",
      "Loading input_2023_w10.csv...\n",
      "  ‚ÑπÔ∏è  Loaded sample: 10,000 rows (out of potentially more)\n",
      "  üíæ Memory: 5.0 MB\n",
      "\n",
      "üìä Sample Output Files:\n",
      "\n",
      "Loading output_2023_w02.csv...\n",
      "  ‚ÑπÔ∏è  Loaded sample: 10,000 rows (out of potentially more)\n",
      "  üíæ Memory: 0.5 MB\n",
      "\n",
      "Loading output_2023_w10.csv...\n",
      "  ‚ÑπÔ∏è  Loaded sample: 10,000 rows (out of potentially more)\n",
      "  üíæ Memory: 0.5 MB\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Sample datasets loaded successfully!\n",
      "================================================================================\n",
      "\n",
      "Note: Weekly files loaded as samples (10,000 rows) to save memory.\n",
      "You can load full files by setting sample_only=False\n",
      "\n",
      "================================================================================\n",
      "üìà DATASET SUMMARY\n",
      "================================================================================\n",
      "\n",
      "‚úì Supplementary data file: 1\n",
      "‚úì Weekly input files: 18\n",
      "‚úì Weekly output files: 18\n",
      "\n",
      "Total files: 37\n",
      "\n",
      "üìã Input files (by week):\n",
      "   ‚Ä¢ input_2023_w01.csv\n",
      "   ‚Ä¢ input_2023_w02.csv\n",
      "   ‚Ä¢ input_2023_w03.csv\n",
      "   ‚Ä¢ input_2023_w04.csv\n",
      "   ‚Ä¢ input_2023_w05.csv\n",
      "   ‚Ä¢ input_2023_w06.csv\n",
      "   ‚Ä¢ input_2023_w07.csv\n",
      "   ‚Ä¢ input_2023_w08.csv\n",
      "   ‚Ä¢ input_2023_w09.csv\n",
      "   ‚Ä¢ input_2023_w10.csv\n",
      "   ‚Ä¢ input_2023_w11.csv\n",
      "   ‚Ä¢ input_2023_w12.csv\n",
      "   ‚Ä¢ input_2023_w13.csv\n",
      "   ‚Ä¢ input_2023_w14.csv\n",
      "   ‚Ä¢ input_2023_w15.csv\n",
      "   ‚Ä¢ input_2023_w16.csv\n",
      "   ‚Ä¢ input_2023_w17.csv\n",
      "   ‚Ä¢ input_2023_w18.csv\n",
      "\n",
      "üìã Output files (by week):\n",
      "   ‚Ä¢ output_2023_w01.csv\n",
      "   ‚Ä¢ output_2023_w02.csv\n",
      "   ‚Ä¢ output_2023_w03.csv\n",
      "   ‚Ä¢ output_2023_w04.csv\n",
      "   ‚Ä¢ output_2023_w05.csv\n",
      "   ‚Ä¢ output_2023_w06.csv\n",
      "   ‚Ä¢ output_2023_w07.csv\n",
      "   ‚Ä¢ output_2023_w08.csv\n",
      "   ‚Ä¢ output_2023_w09.csv\n",
      "   ‚Ä¢ output_2023_w10.csv\n",
      "   ‚Ä¢ output_2023_w11.csv\n",
      "   ‚Ä¢ output_2023_w12.csv\n",
      "   ‚Ä¢ output_2023_w13.csv\n",
      "   ‚Ä¢ output_2023_w14.csv\n",
      "   ‚Ä¢ output_2023_w15.csv\n",
      "   ‚Ä¢ output_2023_w16.csv\n",
      "   ‚Ä¢ output_2023_w17.csv\n",
      "   ‚Ä¢ output_2023_w18.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jp_mi\\AppData\\Local\\Temp\\ipykernel_56468\\548425085.py:19: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def load_and_check_memory(filepath, sample_only=True, nrows=10000):\n",
    "    \"\"\"Load a CSV and report memory usage\"\"\"\n",
    "    \n",
    "    if not filepath.exists():\n",
    "        print(f\"‚ö†Ô∏è  {filepath.name} not found\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nLoading {filepath.name}...\")\n",
    "    \n",
    "    try:\n",
    "        if sample_only:\n",
    "            # Load sample for memory estimation\n",
    "            df = pd.read_csv(filepath, nrows=nrows)\n",
    "            print(f\"  ‚ÑπÔ∏è  Loaded sample: {len(df):,} rows (out of potentially more)\")\n",
    "        else:\n",
    "            # Load full file\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(f\"  ‚úì Loaded: {len(df):,} rows √ó {len(df.columns)} columns\")\n",
    "        \n",
    "        memory_mb = df.memory_usage(deep=True).sum() / (1024**2)\n",
    "        print(f\"  üíæ Memory: {memory_mb:.1f} MB\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error loading: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading datasets (samples)...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load supplementary data\n",
    "print(\"\\nüìä Supplementary Data:\")\n",
    "supp_data = load_and_check_memory(COMPETITION_DIR / 'supplementary_data.csv', sample_only=False)\n",
    "\n",
    "# Load a few weekly input files as examples\n",
    "print(\"\\nüìä Sample Input Files:\")\n",
    "input_w02 = load_and_check_memory(TRAIN_DIR / 'input_2023_w02.csv', sample_only=True)\n",
    "input_w10 = load_and_check_memory(TRAIN_DIR / 'input_2023_w10.csv', sample_only=True)\n",
    "\n",
    "# Load a few weekly output files as examples\n",
    "print(\"\\nüìä Sample Output Files:\")\n",
    "output_w02 = load_and_check_memory(TRAIN_DIR / 'output_2023_w02.csv', sample_only=True)\n",
    "output_w10 = load_and_check_memory(TRAIN_DIR / 'output_2023_w10.csv', sample_only=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Sample datasets loaded successfully!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: Weekly files loaded as samples (10,000 rows) to save memory.\")\n",
    "print(\"You can load full files by setting sample_only=False\")\n",
    "\n",
    "# Count all weekly files\n",
    "input_files = sorted(TRAIN_DIR.glob('input_2023_w*.csv'))\n",
    "output_files = sorted(TRAIN_DIR.glob('output_2023_w*.csv'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà DATASET SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úì Supplementary data file: 1\")\n",
    "print(f\"‚úì Weekly input files: {len(input_files)}\")\n",
    "print(f\"‚úì Weekly output files: {len(output_files)}\")\n",
    "print(f\"\\nTotal files: {1 + len(input_files) + len(output_files)}\")\n",
    "\n",
    "print(\"\\nüìã Input files (by week):\")\n",
    "for f in input_files:\n",
    "    print(f\"   ‚Ä¢ {f.name}\")\n",
    "\n",
    "print(\"\\nüìã Output files (by week):\")\n",
    "for f in output_files:\n",
    "    print(f\"   ‚Ä¢ {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Data download and setup complete! You now have:\n",
    "\n",
    "1. ‚úÖ Competition data downloaded from Kaggle\n",
    "2. ‚úÖ Files extracted to `data/` directory\n",
    "3. ‚úÖ Datasets loaded and verified\n",
    "\n",
    "**Next Steps:**\n",
    "- Continue to `02_exploration.ipynb` to explore the data\n",
    "- Or start analyzing in `03_analysis.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Setup Complete!\n",
      "\n",
      "Next notebook: 02_exploration.ipynb\n",
      "\n",
      "Happy analyzing! üèà\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüéâ Setup Complete!\\n\")\n",
    "print(\"Next notebook: 02_exploration.ipynb\")\n",
    "print(\"\\nHappy analyzing! üèà\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
